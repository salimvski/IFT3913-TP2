- Completer, plan evaluation de qualite du projet JFreeChart
- objectif-question-metrique GQM

- Objectif :
  - analyser la derniere version du code (branche master du JFreeChart)
  - afin d'evaluer son niveau de maintenabilite, (POV chef du projet)
  
- Tache 1:
  TODO :
    - Completer le plan GQM 
    - 2 metriques par question (minimum) 
    - max 9 metriques uniques


Metrique :

- Pourquoi vous pensez que chacune est appropriee et rentable
- Comment prevoyez-vous de la mesurer

1) - Ratio taille code / taille test TODO

  Question : Q3, Q4

  Nous avons choisi cette metrique pour avoir une bonne idee sur la qualite
  des test, ou on suppose que plus le code est complexe plus les test sont consequents
  C'est une metrique approprie pour le projet JFreechart pour avoir une idee sur la 
  qualite des fichiers tests. Cette metrique semble etre aussi simple a mesurer
  et 100% automatisable.

  Afin de mesurer cette metrique nous allons faire le Ratio taille code / taille test
  pour class associee a la taille du fichier test.

2) - Test par classe DONE

  Question: Q4, Q3

  Nous avons choisi cette metrique car il est important d'avoir un bon nombre
  de tests pour tester le code, afin de detecter rapidement les bugs lors de la phase
  developpement d'un projet mais aussi la phase post-developpement d'un projet.
  Cependant, il faut eviter d'avoir beaucoup de test pour des fichier ayant tres
  peu de ligne de code. Cela pourrait baisser la qualite du processus de test.
  Comme JFreeChart semble avoir beaucoup de class il est pertinent de verifier si
  il y a suffisement de test pour chaque package/class.

  Afin de mesurer cette metrique nous pouvons utiliser des outils externes comme
  (GCP) ou bien faire un programme qui nous retourne si les le test coverage est acceptable
  pour un certain seuil.

Comme la qualite des tests est difficilement mesurable, on estime que nous allons
considerer que si nous avons un ratio >= .5, alors le test s'avere concluant.




3) - Complexite cyclomatique TODO

  Question: Q3, Q2, Q4

  Nous avons choisi cette metrique car il est bon de connaitre la complexite 
  cyclomatique de chaque methode d'une class. Il est pertinent de choisir cette
  metrique car du code avec une importante complexite est difficile a test
  et pourrait entrainer des erreurs. Nous avons choisi cette metrique aussi 
  car les tests peuvent etre 100% automatises.

  Pour ce faire nous pouvons utiliser des outils externes comme (GCP, sourceMonitor)
  ou bien creer un script qui calcul la CC pour chaque methode de chaque class


4) - Quantite de commentaire / taille du fichier (documentation/complexite) metric DC  DONE

  Question: Q1, Q3 

  Nous avons choisi cette metrique parce que c'est bon d'avoir des commentaires 
  permettant d'expliquer la complexite d'un code. Surtout quand un nouveau
  developpeur desire travailler sur le projet il gagnera beaucoup en lisant les
  les commentaires du code. 
  Pour mesurer cette metrique nous allons mesurer le pourcentage de commentaires
  par class. Nous allons diviser le nombre de commentaires par le nombre total 
  de ligne de code. Ceci nous donnera un bon indicateur, ou plus il y a de ligne
  de code plus il y a de commentaires.


5) - taille methode/class dans chaque fichier (halstead metrics too, documentation) TODO

  Question: Q1

  Nous avons choisi cette metrique parce que c'est un tres bon indicateur
  sur le complexite du code. En effet, Il est preferable d'avoir un grand nombre
  de petite methodes au lieu de peu de methodes mais de tres longue taille. Ainsi,
  l'analyse du code ce fera de maniere tres facile par des nouvelles personnes 
  par exemple, il est facile de se perdre dans des fonctions qui font des centaines
  et des centaines de lignes de codes.

  Afin de mesurer cette metrique, il y a des outils sur internet afin d'automatiser
  les tests (OTS tools, GCP, sourceMonitor). On doit obtenir une moyenne de taille
  de methode par class/package

6) - Couplage/ DONE

  Question : Q2, Q3

  Nous avons choisi cette metrique car le couplage entre les modules a un 
  impact direct sur la qualite du code ainsi que la maintainabilite. En effet,
  nous pouvons faire des changements facilement entre les modules sans se sourceMonitor
  de l'impact sur les autres modules du systeme. De plus, un faible couplage permet
  d'ecrire du code plus facilement du fait que les modules ne sont pas interdependants.

  Afin de mesurer cette metrique, nous allons utiliser la metrique CSEC utilisee en TP1
  "Couplage simple entre classes" de chaque classe.

7) - Issues DONE

  Question: Q3, Q4.

  Au depart, notre objectif etait d'utiliser Sonar Qube Webservices pour
  recuperer le nombre total de bugs, mais nous avons eu quelques complications,
  c'est donc par ce premier objectif que nous nous sommes dit qu'on allait
  recuperer lenombre de problemes signales sur le projet lui meme, par ses
  propres utilisateurs, le nombre d'Issue d'un project ne reflete pas forcement
  sa qualite, donc, on a decide de recuperer tous les Issues avec le label "bug",
  qui s'avere, au final plus utile que Sonar Qube. Si un projet contient des bugs
  non regles, alors faire des tests autos et sa maturite posent des problemes.
  Il suffit de se donner un seuil, en fonction du projet, pour connaitre le taux
  d'acceptation de bugs.

  Pour cette metrique, nous allons dire que le code doit contenir 0 bug reporte
  pour etre acceptable.

  Afin de mesurer cette metrique, nous avons nous meme implemente la classe, en
  utilisant la docu de l'API de Github.


8) - Age du fichier DONE

  Question: Q3

  Cette metrique nous permet de savoir plus ou moins la frequence de maintenance
  du projet, on peut compter le nombre de commit dans l'annee, et aussi savoir de
  quand date le dernier commit sur la branche Main du repo, si un projet est encore
  maintenu convenablement par la communaute.

  Si il y a eu au moins un commit durant l'annee derniere, alors on considere que 
  le projet est encore maintenu et que le code n'est pas trop vieux.

9) - Duplicat de code

  Question : Q2, Q3

  Cette metrique permet d'avoir une idee sur la complexite de la modularite du code.
  En effet, plus il y aura de la duplication de code plus le code sera complexe
  a maintenir. Techniquement une bonne modularite implique tres peu de duplicat de
  code. Ainsi, il est interessant de mesurer cette metrique pour avoir une idee
  sur la maintenabilite du code, d'autant plus qu'elle semble rentable et 100%
  automatisable. Par ailleurs, cette metrique n'est pas des plus pertinentes bien
  qu'elle sert toujours pour avoir une idee sur la complexite du code.

  Pour mesurer cette metrique, on pourrait utiliser des outils externes tel que,
  GCP


